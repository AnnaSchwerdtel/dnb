#+TITLE:
#+AUTHOR:
#+EMAIL:
#+KEYWORDS:
#+DESCRIPTION:
#+TAGS:
#+LANGUAGE: en
#+OPTIONS: toc:nil ':t H:5
#+STARTUP: hidestars overview
#+LaTeX_CLASS: scrartcl
#+LaTeX_CLASS_OPTIONS: [a4paper,11pt]
#+PANDOC_OPTIONS:

The goal is to enrich the DNB dataset and index it with Elastic.

* process DNB data
** download dump
#+BEGIN_SRC sh :results silent
  curl --output DNBTitel.rdf.gz "http://datendienst.dnb.de/cgi-bin/mabit.pl?cmd=fetch&userID=opendata&pass=opendata&mabheft=DNBTitel.rdf.gz"
#+END_SRC

** convert RDF to JSON
#+BEGIN_SRC sh
  rdf2json.py DNBTitel.rdf.gz | gzip -c > DNBTitel.json.gz
#+END_SRC

** TODO normalise fields
#+BEGIN_SRC sh
  ./json2json.py --normalise DNBTitel.json.gz | gzip -c > DNBTitel_normalised.json.gz
#+END_SRC

What is the difference between ~pages~ and ~extent~?
- ~rdf2json.py~: ~extent~ is from ~dcterms:extent~ and ~pages~ is from
  ~isbd:P1053~ (which is "has extent") - so it is basically the same
- We use ~extent~ when no valid ~pages~ are given.

* analyse fields
We analyse the distribution of some metadata fields.
** pages
** extent
#+BEGIN_SRC sh :results silent
  ./json2json.py --norm --print "pages_norm,extent" DNBTitel.json.gz | sed "s/[0-9]/0/g" | gzip -c > pages_extent.tsv
#+END_SRC

#+BEGIN_SRC sh :results raw
  echo "pages_norm\textent\tfrequency"
  zcat pages_extent.tsv.gz | sort -S1G | uniq -c | head -n20
#+END_SRC

(after some manual tweaking:)

| pages_norm | extent | frequency |
|------------+--------+-----------|
|            |        |   5631051 |
|        000 |        |   4332641 |
|         00 |        |   2895689 |
|            | 00 S.  |   1020134 |
|          0 |        |    172825 |
|       0000 |        |     33250 |
|            | 000 S. |     16541 |
|            | 0 S.   |        95 |
|      00000 |        |        52 |
|     000000 |        |        31 |

So ~extent~ is only given when no (normalised) ~pages~ are given
-> set ~pages_norm~ to pages extracted from ~extent~ in those cases.

** issued
Extract and normalise the patterns for the "issued" field:
#+BEGIN_SRC sh :results silent
  ./json2json.py --norm --print "type,issued" DNBTitel.json.gz | sed "s/[0-9]/0/g" > issued.tsv
#+END_SRC

Let's have a look at the most frequent patterns:
#+BEGIN_SRC sh
  echo "type\tissued pattern\tfrequency"
  sort -S1G issued.tsv | uniq -c | sed -r 's/([0-9]) /\1\t/' | awk -F'\t' '{print $2"\t"$3"\t"$1}' | sort -t$'\t' -nrk3 | head -n20
  echo "*distinct pairs\t\t*" $(sort -S1G -u issued.tsv| wc -l)
#+END_SRC

| type             | issued pattern | frequency |
|------------------+----------------+-----------|
| Document         |           0000 |  10559276 |
| Issue            |           0000 |   1470687 |
| Article          |           0000 |    981040 |
| Collection       |                |    381824 |
| Periodical       |      0000-0000 |    304933 |
| Periodical       |          0000- |    155810 |
| Series           |          0000- |     62002 |
| Series           |              - |     42707 |
| Document         |                |     41579 |
| Periodical       |              - |     25939 |
| Document         |           00XX |     24172 |
| Series           |      0000-0000 |     18156 |
|                  |           0000 |     11070 |
| Collection       |           0000 |      9181 |
| Document         |      0000-0000 |      7250 |
| Periodical       |                |      2849 |
| Collection       |      0000-0000 |      2379 |
| Periodical       |           0000 |       443 |
| Article          |        0000/00 |       331 |
| Article          |          /0000 |       138 |
|------------------+----------------+-----------|
| *distinct pairs* |                |       105 |


Get the valid years for the "Document" type:
#+BEGIN_SRC sh :results silent
  ./json2json.py --normalise --print "type,issued" DNBTitel.json.gz \
      | grep -E '^Document\s+[0-9][0-9][0-9][0-9]$' \
      | awk -F'\t' '{print $2}' | sort | uniq -c | awk '{print $2"\t"$1}' \
						       > issued_document_distrib.tsv
#+END_SRC

Let's plot the years for the "Document" type:
#+BEGIN_SRC gnuplot :results silent
reset
set term svg enhanced size 800,600
set out 'issued.svg'
set grid
set xrange [1450:2050]
set logscale y

set xlabel 'year'
set ylabel 'frequency'

plot "issued_document_distrib.tsv" using 1:2 with lines title ''

set term png enhanced size 800,600
set out 'issued.png'
replot
#+END_SRC

[[issued.png]]

** medium

#+BEGIN_SRC sh
  ./json2json.py -n -p medium DNBTitel.json.gz | sort -S1G | uniq -c
#+END_SRC

| medium                                                  |   count |
|---------------------------------------------------------+---------|
|                                                         |  294526 |
| http://iflastandards.info/ns/isbd/terms/mediatype/T1008 |   19783 |
| RDACarrierType/1018                                     | 4001290 |
| RDACarrierType/1044                                     | 9604425 |
| RDAMediaType/1002                                       |   23059 |
| RDAMediaType/1003                                       |  159226 |

** place

#+BEGIN_SRC sh
  ./json2json.py -n -p place DNBTitel.json.gz | sort -S1G | uniq -c > place.tsv
#+END_SRC

#+BEGIN_SRC sh
  head place.tsv
#+END_SRC

#+RESULTS:
| 5106754 |             |          |                    |      |
|       1 | ['010']     |          |                    |      |
|       1 | ['0rleans'] |          |                    |      |
|       1 | ['1']       |          |                    |      |
|       1 | ['1010      | Wien,    | Blutgasse          | 3']  |
|       1 | ['1010      | Wien,    | Schubertring       | 3']  |
|       3 | ['10179     | Berlin'] |                    |      |
|       1 | ['1037      | Wien,    | Daffingerstraße    | 1']  |
|       1 | ['1050      | Wien,    | Kettenbrückengasse | 3']  |
|       1 | ['1070      | Wien,    | Lindengasse        | 47'] |

** price
** publisher

#+BEGIN_SRC sh
  ./json2json.py -n -p publisher DNBTitel.json.gz | sort -S1G | uniq -c > publisher.tsv
#+END_SRC

** contributor

#+BEGIN_SRC sh
  ./json2json.py -n -p contributor DNBTitel.json.gz | sort -S1G | uniq -c > contributor.tsv
#+END_SRC

* DONE enrich with Wikidata
By using the field ~creator~ (*or should we use ~contributor~?*).

** identify properties
For each entity in Wikidata that has a label, a GND id (P227)
property, and an occupation (P106) property, we extract the following
properties:

| id    | name                                | round | note                    |
|-------+-------------------------------------+-------+-------------------------|
| P106  | occupation                          |   1+2 | condition for inclusion |
| P227  | GND id                              |     1 | condition for inclusion |
| P21   | gender                              |     2 |                         |
| P569  | date of birth                       |     1 |                         |
| P19   | place of birth                      |     2 |                         |
| P625  | - coordinate location               |     2 | extract separately      |
| P570  | date of death                       |     1 |                         |
| P20   | place of death                      |     2 |                         |
| P625  | - coordinate location               |     2 | extract separately      |
| P103  | native language                     |     2 |                         |
| P1412 | languages spoken, written or signed |     2 |                         |
| P166  | awards received                     |     2 |                         |
| P18   | image (P18)                         |     1 |                         |

Approach:
1. find all entities with P106 and P227 and collect all other relevant
   properties
2. get the labels and missing values (e.g., coordinates of cities) for
   properties

** extract subclasses of writer
To label entities whose occupation property points to a subclass of
writer, we extract all subclasses of writer with SPARQL, since this is
faster and simpler than using the dump.

Since an entity can have several values for the occupation property
(e.g., [[https://www.wikidata.org/wiki/Q23][George Washington]]) we extract all values and if one of the
occupations is a subclass of writer, we label the entity as a writer.

We do this with curl as before:
#+BEGIN_SRC sparql :url https://query.wikidata.org/sparql :format text/csv
  SELECT ?subclass
  WHERE
  {
    ?subclass wdt:P279* wd:Q36180
  }
#+END_SRC

#+BEGIN_SRC sh :results silent
  curl \
      --header "Accept: text/tab-separated-values" \
      --output wikidata_writer_subclasses.tsv \
      --globoff \
       'https://query.wikidata.org/sparql?query=SELECT%20%3Fsubclass%20%3FsubclassLabel%0AWHERE%0A%7B%0A%20%20%3Fsubclass%20wdt%3AP279*%20wd%3AQ36180%20.%0A%20%20SERVICE%20wikibase%3Alabel%20%7B%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20...%20include%20the%20labels%0A%20%20%20%20bd%3AserviceParam%20wikibase%3Alanguage%20%22en%22%0A%20%20%7D%0A%7D'
#+END_SRC


#+BEGIN_SRC sh
  wc -l wikidata_writer_subclasses.tsv
#+END_SRC

#+RESULTS:
: 279 wikidata_writer_subclasses.tsv

** DONE process dump

Is done using Java (see ~WriterExtractor.java~ for the basic idea) and
 creates the file ~gndwriter.json~:

> Processed 32346937 entities in 2203 sec (14683 per second)
> read 357423 items and 69577 property values with missing labels


#+BEGIN_SRC sh :results raw
  grep "Goethe" gndwriter.json | sed -e "s/^,/{/" -e "s/$/}/" | json_pp
#+END_SRC

#+BEGIN_SRC json
{
   "118540238" : {
      "id" : "Q5879",
      "name" : "Johann Wolfgang von Goethe",
      "occupations" : [
         {
            "id" : "Q4164507",
            "name" : "art critic"
         },
         {
            "id" : "Q3579035",
            "name" : "travel writer"
         },
         {
            "name" : "poet",
            "id" : "Q49757"
         },
         {
            "id" : "Q1209498",
            "name" : "poet lawyer"
         },
         {
            "name" : "music critic",
            "id" : "Q1350157"
         },
         {
            "name" : "novelist",
            "id" : "Q6625963"
         },
         {
            "name" : "autobiographer",
            "id" : "Q18814623"
         },
         {
            "name" : "playwright",
            "id" : "Q214917"
         },
         {
            "name" : "aphorist",
            "id" : "Q3606216"
         },
         {
            "id" : "Q18939491",
            "name" : "diarist"
         },
         {
            "id" : "Q1234713",
            "name" : "theologian"
         },
         {
            "name" : "art theorist",
            "id" : "Q17391638"
         }
      ]
   }
}
#+END_SRC

** DONE enrich JSON

Modifying ~json2json.py~ to add the Wikidata data for each found
writer with the ~--wikidata~ option.

#+BEGIN_SRC sh
  ./json2json.py -n -w gnditems_2017-08-22_15:03.json DNBTitel.json.gz \
      | gzip -c \
	     > DNBTitel_normalised_enriched.json.gz
#+END_SRC

** test enrichment

#+BEGIN_SRC
  ./json2json.py -n -w gnditems_2017-08-22_15:03.json DNBTitel.json.gz | grep "poet lawyer" > poetlawyer_gndwriter.json
#+END_SRC

#+BEGIN_SRC sh :results raw
  grep Egmont poetlawyer_gndwriter.json | head -n1 | json_pp
#+END_SRC

#+BEGIN_SRC json
{
   "contributor" : [
      "116924373"
   ],
   "title" : "Goethes Egmont in Schillers Bearbeitung",
   "place_publisher" : "München ; Leipzig : G. Müller",
   "publisher" : "G. Müller",
   "place" : [
      "München",
      "Leipzig"
   ],
   "issued" : "1914",
   "lang" : "ger",
   "pages" : [
      "153 S."
   ],
   "medium" : "RDACarrierType/1044",
   "_id" : "361432887",
   "pages_norm" : 153,
   "creator_wd" : {
      "118540238" : {
         "languages" : "German",
         "image" : "Goethe (Stieler 1828).jpg",
         "place_of_death" : "Weimar",
         "native_language" : "German",
         "id" : "Q5879",
         "date_of_death" : "1832-03-22",
         "date_of_birth" : "1749-08-28",
         "name" : "Johann Wolfgang von Goethe",
         "awards" : [
            "Merit Order of the Bavarian Crown",
            "Officer of the Legion of Honour",
            "Order of Saint Anna, 1st class"
         ],
         "place_of_birth" : "Frankfurt",
         "gender" : "male",
         "occupation" : [
            "poet lawyer",
            "theatre manager",
            "botanist",
            "politician",
            "painter",
            "philosopher",
            "theologian",
            "jurist",
            "art critic",
            "music critic",
            "Geheimrat",
            "librarian",
            "poet",
            "travel writer",
            "physicist",
            "literary",
            "novelist",
            "playwright",
            "autobiographer",
            "diplomat",
            "statesman",
            "polymath",
            "aphorist",
            "diarist",
            "mineralogist",
            "zoologist",
            "art theorist",
            "lawyer"
         ],
         "occupation_writer" : [
            "poet lawyer",
            "theologian",
            "art critic",
            "music critic",
            "poet",
            "travel writer",
            "novelist",
            "playwright",
            "autobiographer",
            "aphorist",
            "diarist",
            "art theorist"
         ]
      }
   },
   "type" : "Document",
   "issued_norm" : 1914,
   "creator" : [
      "118540238"
   ]
}
#+END_SRC

** attic

Manually download (a part of) the Wikidata dump (since Java gets a 503
and disk space is scarce):
#+BEGIN_SRC sh
  # this fixes
  zcat 20170814.json.gz_ORIG | head -n -2 | head -c -2 | sed -e "\$a]" | gzip -c > 20170814.json.gz
#+END_SRC

* TODO index in Elastic

- check what happens with JSON like this: "publisher":
  "Akad. Kiado\u0301" - is the [[http://www.fileformat.info/info/unicode/char/0301/index.htm][COMBINING ACUTE ACCENT]] correctly
  processed? similar: "publisher": "Museum fu\u0308r Tierkunde"
Queries:
- Median, Mean, etc. in Elastic? - [[https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-metrics-percentile-aggregation.html][percentiles]]
- location (format "lat,lon" should work)

** TODO create index

TODO: add Wikidata fields

| field             | type    | analysed | note                                           |
|-------------------+---------+----------+------------------------------------------------|
| ~_id~             | string  | no       | DNB ID                                         |
| ~contributor~     | string  |          |                                                |
| ~creator~         | string  |          |                                                |
| ~extent~          | string  |          | field is missing! *TODO: difference to pages?* |
| ~issued~          | string  |          |                                                |
| ~issued_norm~     | integer | no       | year                                           |
| ~lang~            | string  | no       | 3-letter code or empty                         |
| ~medium~          | string  | no       |                                                |
| ~pages~           | string  | no       |                                                |
| ~pages_norm~      | integer | no       |                                                |
| ~place~           | string  |          |                                                |
| ~place_publisher~ | string  |          |                                                |
| ~price~           | string  |          |                                                |
| ~publisher~       | string  |          |                                                |
| ~short_title~     | string  |          |                                                |
| ~subject~         | string  |          |                                                |
| ~title~           | string  | yes      |                                                |
| ~type~            | string  | no       |                                                |

** fill index

* TODO analysis
data filters:
1. issued >= 1912
2. author has [[https://www.wikidata.org/wiki/Property:P227][GND id]] in Wikidata
3. author has [[https://www.wikidata.org/wiki/Property:P106][occupation]] that is a [[https://www.wikidata.org/wiki/Property:P279][subclass]] of [[https://www.wikidata.org/wiki/Q36180][writer]]
4. work has a page number (extent)

for publishers:
5. limit maximal number of pages per work to exclude outliers (e.g., to 5000)

** DONE media types

All media:
#+BEGIN_SRC sh
  ./json2json.py -f -p type DNBTitel_normalised_enriched.json.gz \
      | sort -S1G | uniq -c > media_freq.tsv
#+END_SRC

With usable page numbers:
#+BEGIN_SRC sh :results silent
  ./json2json.py -f -p type,pages_norm \
		 DNBTitel_normalised_enriched.json.gz \
      | cut -f1 | sort -S1G | uniq -c > media_with_pages_freq.tsv
#+END_SRC

With all data filters except >= 1912:
#+BEGIN_SRC sh :results silent
  ./json2json.py -f -p "type,pages_norm,creator_wd.*.occupation_writer" \
		 DNBTitel_normalised_enriched.json.gz \
      | cut -f1 | sort -S1G | uniq -c > media_filtered_freq.tsv
#+END_SRC

With all data filters:
#+BEGIN_SRC sh :results silent
  ./json2json.py -f -p "issued,type,pages_norm,creator_wd.*.occupation_writer" \
		 DNBTitel_normalised_enriched.json.gz \
      | awk -F'\t' '{if ($1 >= 1912) print $2}' \
      | sort -S1G | uniq -c > media_filtered_1912_freq.tsv
#+END_SRC

Combine into a table:
#+BEGIN_SRC sh
  cat media_freq.tsv
  echo "---"
  cat media_with_pages_freq.tsv
  echo "---"
  cat media_filtered_freq.tsv
  echo "---"
  cat media_filtered_1912_freq.tsv
#+END_SRC

| type       |     freq | freq (pages given) | freq (filtered) | freq (filtered, >= 1912) |
|------------+----------+--------------------+-----------------+--------------------------|
|            |    11070 |                    |                 |                          |
| Article    |   981677 |                    |                 |                          |
| Collection |   393390 |                347 |              39 |                        1 |
| Document   | 10632628 |            7434113 |         1047801 |                  1030524 |
| Issue      |  1470688 |            1036770 |                 |                          |
| Periodical |   489990 |                  8 |                 |                          |
| Series     |   122866 |                 20 |                 |                          |
|------------+----------+--------------------+-----------------+--------------------------|
| *sum*      | 14102309 |            8471258 |         1047840 |                  1030525 |
#+TBLFM: @9$2=vsum(@I..@II)::@9$3=vsum(@I..@II)::@9$4=vsum(@I..@II)::@9$5=vsum(@I..@II)

** DONE number of pages

Filter data:
#+BEGIN_SRC sh
  ./json2json.py -f -p "issued,pages_norm,creator_wd.*.occupation_writer" \
		 DNBTitel_normalised_enriched.json.gz \
      | awk -F'\t' '{if ($1 >= 1912) print $2}' > pages.tsv
#+END_SRC

Count frequencies:
#+BEGIN_SRC sh :results silent
  sort -n -S1G pages.tsv | uniq -c | awk '{print $2"\t"$1}' | sort -n > pages_freq.tsv
#+END_SRC

Plot distribution:
#+BEGIN_SRC gnuplot :results silent
reset
set term svg enhanced size 800,600
set out 'pages.svg'
set grid
set xrange [0:4000]
set logscale y
set format y "10^%T"

set xlabel 'number of pages'
set ylabel 'frequency'

plot 'pages_freq.tsv' using 1:2 with lines title ''

set term png enhanced size 800,600
set out 'pages.png'
replot


# showing bogen boundaries
unset logscale
unset format y
set xtics 0,16


# zoom into range 400 to 600 to see 16-patterns of pages
set xrange [400:600]
set term png enhanced size 800,600
set out 'pages_400-600.png'
plot 'pages_freq.tsv' using 1:2 with lines title ''

set term svg enhanced size 800,600
set out 'pages_400-600.svg'
replot


# zoom into range 200 to 400 to see 16-patterns of pages
set xrange [200:400]
set term png enhanced size 800,600
set out 'pages_200-400.png'
plot 'pages_freq.tsv' using 1:2 with lines title ''

set term svg enhanced size 800,600
set out 'pages_200-400.svg'
replot


# zoom into range 0 to 200 to see 16-patterns of pages
set xrange [0:200]
set term png enhanced size 800,600
set out 'pages_000-200.png'
plot 'pages_freq.tsv' using 1:2 with lines title ''

set term svg enhanced size 800,600
set out 'pages_000-200.svg'
replot
#+END_SRC

**** page distribution
[[pages.png]]

**** page ranges
[[pages_000-200.png]]

[[pages_200-400.png]]

[[pages_400-600.png]]

** DONE top authors

- TODO: plot distribution of the number of authors per work

*** by item count
#+BEGIN_SRC sh
  ./json2json.py -f -p "issued,pages_norm,creator_wd.*.occupation_writer,creator_wd.*.name,creator_wd.*.id" \
		 DNBTitel_normalised_enriched.json.gz \
      | awk -F'\t' '{if ($1 >= 1912) print $4"\t"$5}' \
      | sort -S1G | uniq -c | sort -nr | head -n20
#+END_SRC

| author                     | frequency |
|----------------------------+-----------|
| [[https://www.wikidata.org/wiki/Q5879][Johann Wolfgang von Goethe]] |      5090 |
| [[https://www.wikidata.org/wiki/Q78484][Rudolf Steiner]]             |      3965 |
| [[https://www.wikidata.org/wiki/Q25973][Hermann Hesse]]              |      3337 |
| [[https://www.wikidata.org/wiki/Q60753][Heinz G. Konsalik]]          |      3191 |
| [[https://www.wikidata.org/wiki/Q37030][Thomas Mann]]                |      2507 |
| [[https://www.wikidata.org/wiki/Q78491][Stefan Zweig]]               |      2482 |
| [[https://www.wikidata.org/wiki/Q905][Franz Kafka]]                |      2017 |
| [[https://www.wikidata.org/wiki/Q22670][Friedrich Schiller]]         |      2003 |
| [[https://www.wikidata.org/wiki/Q26993][Theodor Storm]]              |      1951 |
| [[https://www.wikidata.org/wiki/Q6701][Jacob Grimm]], [[https://www.wikidata.org/wiki/Q6714][Wilhelm Grimm]] |      1932 |
| [[https://www.wikidata.org/wiki/Q38757][Bertolt Brecht]]             |      1905 |
| [[https://www.wikidata.org/wiki/Q76546][Erich Kästner]]              |      1864 |
| [[https://www.wikidata.org/wiki/Q9358][Friedrich Nietzsche]]        |      1778 |
| [[https://www.wikidata.org/wiki/Q42747][Heinrich Böll]]              |      1769 |
| [[https://www.wikidata.org/wiki/Q692][William Shakespeare]]        |      1700 |
| [[https://www.wikidata.org/wiki/Q110382][Marie Louise Fischer]]       |      1677 |
| [[https://www.wikidata.org/wiki/Q76483][Rainer Maria Rilke]]         |      1658 |
| [[https://www.wikidata.org/wiki/Q122370][Gottfried Keller]]           |      1657 |
| [[https://www.wikidata.org/wiki/Q9554][Martin Luther]]              |      1598 |
| [[https://www.wikidata.org/wiki/Q45330][Anselm Grün]]                |      1552 |

*** by page count
#+BEGIN_SRC sh
  ./json2json.py -f -p "issued,pages_norm,creator_wd.*.name,creator_wd.*.occupation_writer" \
		 DNBTitel_normalised_enriched.json.gz \
      | awk -F'\t' '{if ($1 >= 1912) {sum[$3]+=$2; count[$3]+=1}} END {for (p in sum) printf("%s\t%s\t%s\t%s\n",  sum[p], count[p], int(sum[p]/count[p]), p)}' \
      | sort -S1G -nr | head -n20
#+END_SRC

| author                     |   pages | items | average pages |
|----------------------------+---------+-------+---------------|
| Johann Wolfgang von Goethe | 1177220 |  5090 |           231 |
| Heinz G. Konsalik          |  983158 |  3191 |           308 |
| Thomas Mann                |  929002 |  2507 |           370 |
| Hermann Hesse              |  738020 |  3337 |           221 |
| Rudolf Steiner             |  692874 |  3965 |           174 |
| Stefan Zweig               |  670878 |  2482 |           270 |
| Franz Kafka                |  538311 |  2017 |           266 |
| Fyodor Dostoyevsky         |  529792 |  1086 |           487 |
| Karl May                   |  507948 |  1504 |           337 |
| Friedrich Nietzsche        |  472457 |  1778 |           265 |
| Lion Feuchtwanger          |  459691 |  1022 |           449 |
| Theodor Fontane            |  450836 |  1548 |           291 |
| Marie Louise Fischer       |  435997 |  1677 |           259 |
| Colleen McCullough         |  424189 |   143 |          2966 |
| Erich Maria Remarque       |  414153 |  1179 |           351 |
| Leo Tolstoy                |  395758 |  1077 |           367 |
| Heinrich Böll              |  388619 |  1769 |           219 |
| Friedrich Schiller         |  383585 |  2003 |           191 |
| Stephen King               |  380219 |   799 |           475 |
| Sigmund Freud              |  377503 |  1494 |           252 |

*** by average page count

#+BEGIN_SRC sh :results silent
  ./json2json.py -f -p "issued,pages_norm,creator_wd.*.name,creator_wd.*.occupation_writer" \
		 DNBTitel_normalised_enriched.json.gz \
      | awk -F'\t' '{if ($1 >= 1912) {sum[$3]+=$2; count[$3]+=1}} END {for (p in sum) printf("%s\t%s\t%s\t%s\n",  sum[p], count[p], int(sum[p]/count[p]), p)}' \
	    > author_pages_stats.tsv
#+END_SRC

#+BEGIN_SRC sh
  sort -S1G -nrk3 author_pages_stats.tsv | head -n20
#+END_SRC

| author                              |  pages | items | average pages | work                             |
|-------------------------------------+--------+-------+---------------+----------------------------------|
| Reinhard Baumgart                   | 340491 |    32 |         10640 |                                  |
| Samael Aun Weor                     | 141110 |    27 |          5226 |                                  |
| Günther Bentele                     | 103739 |    27 |          3842 |                                  |
| Jean Quatremer                      |   3376 |     1 |          3376 | [[http://d-nb.info/959702911][Ces hommes qui ont fait l'euro]]   |
| Pierre Alexis Ponson du Terrail     |   3200 |     1 |          3200 |                                  |
| Colleen McCullough                  | 424189 |   143 |          2966 |                                  |
| Dieter Hildebrandt                  | 266207 |   100 |          2662 |                                  |
| André Vauchez                       |   2536 |     1 |          2536 | [[http://d-nb.info/931339286][Gottes vergessenes Volk]]          |
| Wolfgang Lauterbach, Peter Hartmann |   2319 |     1 |          2319 | [[http://d-nb.info/730214605][Zivilprozessordnung]]              |
| Peter Hartmann                      | 101951 |    46 |          2216 |                                  |
| Wolfgang Kleiber                    |  10787 |     5 |          2157 |                                  |
| Noam Chomsky                        | 197964 |    92 |          2151 |                                  |
| Thomas Fischer, Herbert Tröndle     |   2052 |     1 |          2052 | [[http://d-nb.info/955718287][Strafgesetzbuch und Nebengesetze]] |
| Kari Jormakka                       |  10239 |     5 |          2047 |                                  |
| John Bernard Burke                  |   4052 |     2 |          2026 | [[http://d-nb.info/450713768][450713768]], [[http://d-nb.info/982125054][982125054]]             |
| Egon Wiberg, Arnold F. Holleman     |   5633 |     3 |          1877 |                                  |
| Frank Göttmann                      |   5561 |     3 |          1853 |                                  |
| Lutz Meyer-Goßner                   |  25432 |    14 |          1816 |                                  |
| Walter Bayer, Marcus Lutter         |   1779 |     1 |          1779 |                                  |
| Marthe Vogt, Walter Pagel           |   1770 |     1 |          1770 |                                  |

There are probably some errors among those ...

#+BEGIN_SRC gnuplot :results silent
reset
set encoding utf8
set term png enhanced size 800,600
set out 'author_pages.png'

set grid
set datafile separator "\t"
set xrange [*:10000]
set logscale
set format y "10^%T"
set format x "10^%T"

set xlabel 'number of items'
set ylabel 'mean number of pages per item'

#set label "Peter Goetz von Olenhusen" left at 1, 190192 offset .5,.5
#set label "Antoine Furetiere" left at 2, 11462 offset .5, .5
set label "Reinhard Baumgart" left at 32, 10640 offset .5, .3
set label "Colleen McCullough" left at 143, 2966 offset .5, .3
set label "Samael Aun Weor" left at 27, 5226 offset .5, .3
set label "Guenther Bentele" left at 27, 3842 offset .5, .3
set label "Johann\nWolfgang\nvon\nGoethe" left at 5221, 230 offset -1.8, 3.6

plot 'author_pages_stats.tsv' using 2:3 with points pt 7 title ''

set term svg enhanced size 800,600
set out 'author_pages.svg'
replot
#+END_SRC

[[author_pages.png][author_pages.png]]

** top works

#+BEGIN_SRC sh
  ./json2json.py -f -p "issued,pages_norm,title,_id,creator_wd.*.occupation_writer" \
		 DNBTitel_normalised_enriched.json.gz \
      | awk -F'\t' '{if ($1 >= 1912) {print $2"\t[[http://d-nb.info/"$4"]["$3"]]"}}' \
      | sort -S1G -nr | head -n20
#+END_SRC

| title                                        |  pages |
|----------------------------------------------+--------|
| [[http://d-nb.info/920918131][Tim]]                                          | 348333 |
| [[http://d-nb.info/930916484][Selbstvergessenheit]]                          | 332331 |
| [[http://d-nb.info/920996760][Denkzettel]]                                   | 239240 |
| [[http://d-nb.info/880974125][Die fünfte Freiheit]]                          | 176150 |
| [[http://d-nb.info/942067983][Revolutionäre Psychologie]]                    | 137317 |
| [[http://d-nb.info/959654496][Die Malerei im Bietigheimer Hornmoldhaus]]     |  96104 |
| [[http://d-nb.info/1112954090][Kostengesetze]]                                |  22297 |
| [[http://d-nb.info/820541613][Die grünen Augen]]                             |  21920 |
| [[http://d-nb.info/958168091][Nicht mehr rauchen und dabei schlank bleiben]] |  13008 |
| [[http://d-nb.info/964760746][Flying Dutchmen]]                              |   9306 |
| [[http://d-nb.info/964186179][Fado Alexandrino]]                             |   7969 |
| [[http://d-nb.info/36896809X][Il giuoco delle perle di vetro]]               |   5616 |
| [[http://d-nb.info/947104364][Getreidemarkt am Bodensee]]                    |   5126 |
| [[http://d-nb.info/975045431][Die Waffen nieder!]]                           |   4292 |
| [[http://d-nb.info/997086467][Aeneis]]                                       |   4290 |
| [[http://d-nb.info/970072074][Fastnachtsspiele, Tragödien und Komödien]]     |   4114 |
| [[http://d-nb.info/105133537X][Zivilprozessordnung]]                          |   3401 |
| [[http://d-nb.info/959702911][Ces hommes qui ont fait l'euro]]               |   3376 |
| [[http://d-nb.info/576168084][Complete Works]]                               |   3360 |
| [[http://d-nb.info/944603440][Das grosse Buch der Olympischen Spiele]]       |   3320 |

** TODO publishers and pages
5. Hauptanliegen sollten für dieses Mal die Verlage und deren
Seitenpolitik sein: Durchschnittliche Länge von Büchern pro Verlag
(Suhrkamp, Rowohlt, Aufbau, Hanser, Eichborn, …) – wobei ich hier Bücher
über 5.000 Seiten weglassen würde, weil das offenbar Fehler sind. – Und
ein Längenranking (Top-20?) pro Verlag – die kann man dann
handbereinigen, falls mal nichtliterarische Werke darunter gefallen
sind, denn es sind ja nicht so viele in einer Top-20-Liste.

*Frage: wieviel Aufwand in die Normalisierung der Verlage stecken?*
Optionen:
- nicht normalisieren
- einige wenige Verlage normalisieren

*** DONE most frequent publishers

#+BEGIN_SRC sh :results silent
  ./json2json.py -n -p publisher DNBTitel.json.gz | sort -S1G | uniq -c | gzip -c > publisher.tsv.gz
#+END_SRC

Top publishers:
#+BEGIN_SRC sh
  zcat publisher.tsv.gz | sort -S1G -nr | head -n20
#+END_SRC

| publisher                       |   items |
|---------------------------------+---------|
|                                 | 5640251 |
| GRIN Verlag GmbH                |  121456 |
| Books on Demand                 |   97716 |
| Springer                        |   83093 |
| LAP LAMBERT Academic Publishing |   83033 |
| [s. n.]                         |   78068 |
| Springer Berlin Heidelberg      |   54125 |
| Lang                            |   54075 |
| John Wiley & Sons               |   50768 |
| Heyne                           |   42233 |
| Rowohlt                         |   40982 |
| VDM Verlag Dr. Müller           |   40954 |
| tredition                       |   32839 |
| [s.n.]                          |   32549 |
| Herder                          |   31734 |
| GRIN Verlag                     |   31242 |
| Shaker                          |   29769 |
| Goldmann                        |   27502 |
| Beck                            |   27324 |
| Reclam                          |   26953 |

**** But: beware of errors
#+BEGIN_SRC sh
  zcat publisher.tsv.gz | sort -S1G -nr | grep Brockhaus | head -n20
#+END_SRC

| label                                          | frequency |
|------------------------------------------------+-----------|
| Brockhaus                                      |      5968 |
| R. Brockhaus                                   |       868 |
| F. A. Brockhaus                                |       671 |
| Brockhaus, VEB                                 |       543 |
| SCM R. Brockhaus                               |       494 |
| SCM R.Brockhaus im SCM-Verlag                  |       221 |
| VEB Brockhaus                                  |       193 |
| Bibliogr. Inst. und Brockhaus                  |       121 |
| [F. A. Brockhaus]                              |        65 |
| Brockhaus VEB                                  |        63 |
| Bibliogr. Inst. & Brockhaus                    |        62 |
| F. A. Brockhaus Verlag                         |        53 |
| Brockhaus, Wissenmedia in der InmediaONE] GmbH |        50 |
| SCM R. Brockhaus im SCM Verlag GmbH & Co.KG    |        38 |
| Theologischer Verlag Brockhaus                 |        34 |
| [Brockhaus]                                    |        30 |
| SCM R.Brockhaus                                |        25 |
| Theologischer Verl. Brockhaus                  |        16 |
| M. Brockhaus                                   |         9 |
| SCM Brockhaus                                  |         8 |
*** TODO average extent per publisher
**** extract raw data
#+BEGIN_SRC sh
  ./json2json.py -n -p publisher,pages_norm | gzip -c > publisher_pages.tsv.gz
#+END_SRC
**** DONE filter outliers and errors
remove:
- pages > 5000
- no pages
- no publisher

#+BEGIN_SRC sh
  zcat publisher_pages.tsv.gz \
      | awk -F'\t' '{if ($1 != "" && $2 != "" && $2 <= 5000) print $1"\t"$2}' \
      | gzip -c > publisher_pages_filtered.tsv.gz
#+END_SRC

**** TODO ranking per publisher

have to clarify normalisation first


**** DONE average book length per publisher

# would be easy with sqlite3 - install!

Count per publisher:
#+BEGIN_SRC sh :results silent
  zcat publisher_pages_filtered.tsv.gz \
      | awk -F'\t' '{sum[$1]+=$2; count[$1]+=1} END {for (p in sum) printf("%s\t%s\t%s\t%s\n", p, sum[p], count[p], int(sum[p]/count[p]))}' \
	    > publisher_pages_stats.tsv
#+END_SRC

***** top 20 by page sum
#+BEGIN_SRC sh
  sort -t$'\t' -rnk2 publisher_pages_stats.tsv | head -n20
#+END_SRC

| publisher                          |    pages | items | mean |
|------------------------------------+----------+-------+------|
| Springer                           | 21319843 | 65100 |  327 |
| Lang                               | 14134698 | 51255 |  276 |
| Heyne                              | 12587106 | 41094 |  306 |
| Beck                               | 10391848 | 24630 |  422 |
| Rowohlt                            |  9237092 | 40148 |  230 |
| Goldmann                           |  7776002 | 26491 |  294 |
| Herder                             |  5811171 | 29036 |  200 |
| Suhrkamp                           |  5675784 | 21129 |  269 |
| Ullstein                           |  5310460 | 19025 |  279 |
| Reclam                             |  4885858 | 25831 |  189 |
| Dt. Taschenbuch-Verl.              |  4489154 | 17122 |  262 |
| Piper                              |  4349318 | 14524 |  299 |
| Fischer-Taschenbuch-Verl.          |  4060245 | 14549 |  279 |
| Shaker                             |  4013108 | 22838 |  176 |
| RM-Buch-und-Medien-Vertrieb [u.a.] |  3813996 | 11215 |  340 |
| Weltbild                           |  3586937 | 10636 |  337 |
| Oldenbourg                         |  3469927 | 11820 |  294 |
| Thieme                             |  3317355 | 12559 |  264 |
| de Gruyter                         |  3281362 | 10534 |  312 |
| Kohlhammer                         |  3239885 | 14734 |  220 |

***** top 20 by mean page count

#+BEGIN_SRC sh
   sort -t$'\t' -rnk4 publisher_pages_stats.tsv | head -n20
#+END_SRC

| publisher                                                                    | pages | items | mean |
|------------------------------------------------------------------------------+-------+-------+------|
| Ronny Szpetecki                                                              |  4676 |     1 | 4676 |
| Kantonale Denkmalpflege Graubünden                                           |  4248 |     1 | 4248 |
| Großversandhaus Quelle                                                       |  3947 |     1 | 3947 |
| Didacta, Ausstellungs- und Verl.-Ges.                                        |  3700 |     1 | 3700 |
| Chemical Rubber Publishing Co.                                               |  3604 |     1 | 3604 |
| Deutscher Sparkassenverlag Stuttgart                                         |  3295 |     1 | 3295 |
| Ander                                                                        |  6398 |     2 | 3199 |
| Maṭbaʿat al-Ahrām                                                            |  3056 |     1 | 3056 |
| Deutsche Demokratische Republik, Staatl. Plankommission, Statist. Zentralamt |  2967 |     1 | 2967 |
| Burke's Peerage Ltd.                                                         |  2867 |     1 | 2867 |
| [PONS GmbH]                                                                  |  2837 |     1 | 2837 |
| Life Publ. International                                                     |  2776 |     1 | 2776 |
| Genfer Bibelgesellschaft                                                     |  2673 |     1 | 2673 |
| Hakubunkan Verl.                                                             |  2633 |     1 | 2633 |
| McClelland and Stewart Inc.                                                  |  2573 |     1 | 2573 |
| Schraad                                                                      |  2560 |     1 | 2560 |
| Verlagsh. Freya G. m. b. H.                                                  |  2516 |     1 | 2516 |
| Monte Avila                                                                  |  2516 |     1 | 2516 |
| Pierer, Heymann                                                              |  2500 |     1 | 2500 |
| Jixie-Gongye-Chubanshe                                                       |  2462 |     1 | 2462 |
***** scatter plot

How is the number of items per publisher related to the average number
of pages per publisher?

#+BEGIN_SRC gnuplot :results silent
reset
set term png enhanced size 800,600
set out 'publisher_pages.png'

set grid
set datafile separator "\t"
set logscale

set xlabel 'number of items
set ylabel 'mean number of pages per item'

plot 'publisher_pages_stats.tsv' using 3:4 with points pt 7 title ''

set term svg enhanced size 800,600
set out 'publisher_pages.svg'
replot
#+END_SRC

[[publisher_pages.png]]

** temporal distribution
Let's plot the median number of pages per decade:

#+BEGIN_SRC sh
  LC_ALL=C ./json2json.py -p "issued,pages_norm,creator_wd.*.occupation_writer" DNBTitel_normalised_enriched.json.gz \
      | awk -F'\t' '{if ($1 != "" && $2 != "" && $3 != "") print int($1/10)"\t"$2}' \
      | sort -S1G -nr \
      | datamash -g 1 median 2 mean 2 min 2 max 2 count 2 q1 2 q3 2\
		 > decade_pages_stats.tsv
#+END_SRC

#+BEGIN_SRC gnuplot :results silent
reset
set encoding utf8
set term png enhanced size 800,600
set out 'decade_pages.png'

set grid
set datafile separator "\t"
set xrange [1500:2020]
set xlabel 'year'
set ylabel number of pages per decade'

plot \
  'decade_pages_stats.tsv' using ($1*10):7:8 with filledcurves fs transparent solid 0.2 noborder lc rgb "green" title '1st and 3rd quartile',\
  'decade_pages_stats.tsv' using ($1*10):2 with linespoints pt 7 lw 2 lt 3 lc rgb "green" title 'median'

set term svg enhanced size 800,600
set out 'decade_pages.svg'
replot
#+END_SRC

[[decade_pages.png]]
